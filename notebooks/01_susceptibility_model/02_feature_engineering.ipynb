{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "This notebook runs neighborhood feature generation (lattice averages). Make sure to download the necssary input files and match them to the directories listed below.\n",
    "\n",
    "### Input\n",
    "- Training data from `01_create_training_data.ipynb`\n",
    "- Features table\n",
    "- Bingtile x and y coordinates\n",
    "\n",
    "### Output\n",
    "- training data with the neighborhood aggregates of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Set up\n",
    "\n",
    "*DO NOT SKIP THIS SECTION.* This section imports the packages needed to run this notebook and initializes the data file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbymoreno/miniconda3/envs/immap-evidem/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.3-CAPI-1.16.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import polars as pl\n",
    "from polars import selectors as cs\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../\")  # include parent directory\n",
    "from src.polars_utils import log_condition, log_duplicates\n",
    "from src import bing_tile_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.settings import DATA_DIR\n",
    "\n",
    "MODEL_DIR = DATA_DIR / \"models\"\n",
    "ADMIN_DIR = DATA_DIR / \"admin_bounds\"\n",
    "OUTPUT_DIR = DATA_DIR / \"output/component_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VERSION = \"20240503\"\n",
    "TRAIN_TABLE_FPATH = MODEL_DIR / f\"training_data/training_data_{TRAIN_VERSION}.parquet\"\n",
    "\n",
    "BINGTILE_FPATH = ADMIN_DIR / f\"grids_landslide_w_xyz_zoomlevel18_20240320.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the function parameters/arguments that are necessary for the rest of the steps. For the `BING_TILE_ZOOM_LEVEL` make sure that is is the same as the zoom level for our base grids. For the `LATTICE_RADIUS`, this can be adjusted based on the neighborhood size that you want to consider in studying the area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice variables\n",
    "BING_TILE_ZOOM_LEVEL = 18\n",
    "USE_WEIGHTED_LATTICE = False\n",
    "LATTICE_RADIUS = 3\n",
    "CHEBYSHEV_DIST_COL = \"chebyshev_dist_col\"\n",
    "\n",
    "OUTPUT_VERSION = pd.to_datetime(\"today\").strftime(\"%Y%m%d\")\n",
    "OUTPUT_FPATH = (\n",
    "    MODEL_DIR\n",
    "    / f\"training_data/training_data_w_lattice{LATTICE_RADIUS}_{OUTPUT_VERSION}.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bingtiles = pl.read_parquet(BINGTILE_FPATH)\n",
    "bingtiles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = pl.read_parquet(TRAIN_TABLE_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__index_level_0__\" in train_table.columns:\n",
    "    train_table = train_table.drop(\"__index_level_0__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = train_table.fill_null(\"non_landslide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table[\"MOV_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pl.read_parquet(TRAIN_TABLE_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove nulls and impute values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rainfall median\n",
    "features_df = features_df.with_columns(\n",
    "    pl.when(pl.col(\"rainfall_mm_median\") < 0)\n",
    "    .then(0)\n",
    "    .otherwise(pl.col(\"rainfall_mm_median\"))\n",
    "    .alias(\"rainfall_mm_median\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get lattices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get weight expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs_dict = bing_tile_utils.get_lattice_weight_exprs(\n",
    "    use_weighted_lattice=USE_WEIGHTED_LATTICE,\n",
    "    radius=LATTICE_RADIUS,\n",
    "    group_by_cols=\"center_quadkey\",\n",
    "    chebyshev_dist_col=CHEBYSHEV_DIST_COL,\n",
    ")\n",
    "\n",
    "chebyshev_count_exprs = exprs_dict[\"chebyshev_count_exprs\"]\n",
    "lattice_weight_exprs = exprs_dict[\"lattice_weight_exprs\"]\n",
    "lattice_weight_multiplier = exprs_dict[\"lattice_weight_multiplier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add X and Y components to quadkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df = train_table.join(bingtiles, on=\"quadkey\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df = landslide_df.with_columns(\n",
    "    pl.col(\"x\").cast(pl.Int64),\n",
    "    pl.col(\"y\").cast(pl.Int64),\n",
    "    pl.col(\"z\").cast(pl.Int64),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df[\"MOV_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landslide_df.select(\"*\").null_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"quadkey\", \"x\", \"y\"]\n",
    "landslide_quadkeys = (\n",
    "    landslide_df.pipe(log_duplicates, columns)\n",
    "    .unique()\n",
    "    .pipe(log_condition, pl.any_horizontal([pl.col(\"*\").is_null()]))\n",
    "    .drop_nulls()\n",
    ")\n",
    "landslide_quadkeys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_tile_utils.get_bing_cluster_tile_length_m(BING_TILE_ZOOM_LEVEL, LATTICE_RADIUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_df = bing_tile_utils.generate_lattice(\n",
    "    landslide_quadkeys.select(\"x\", \"y\"),\n",
    "    LATTICE_RADIUS,\n",
    "    zoom_level=BING_TILE_ZOOM_LEVEL,\n",
    "    include_chebyshev_dist=USE_WEIGHTED_LATTICE,\n",
    ")\n",
    "assert not lattice_df.is_duplicated().any()\n",
    "\n",
    "print(len(lattice_df))\n",
    "lattice_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {\"x\": \"center_x\", \"y\": \"center_y\", \"quadkey\": \"center_quadkey\"}\n",
    "columns = [\"center_quadkey\", \"lattice_quadkey\"]\n",
    "if USE_WEIGHTED_LATTICE:\n",
    "    columns += bing_tile_utils.CHEBYSHEV_DIST_COLS\n",
    "\n",
    "lattice_df = lattice_df.join(\n",
    "    landslide_quadkeys.rename(rename_dict), on=[\"center_x\", \"center_y\"], how=\"left\"\n",
    ").select(columns)\n",
    "print(len(lattice_df))\n",
    "lattice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate lattice aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features that need the average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_cols = [\n",
    "    \"elevation_median\",\n",
    "    \"slope_median\",\n",
    "    \"aspect_median\",\n",
    "    \"hillshade_median\",\n",
    "    \"rainfall_mm_median\",\n",
    "    \"sand_5-15cm_mean\",\n",
    "    \"sand_100-200cm_mean\",\n",
    "    \"silt_5-15cm_mean\",\n",
    "    \"silt_100-200cm_mean\",\n",
    "    \"clay_5-15cm_mean\",\n",
    "    \"clay_100-200cm_mean\",\n",
    "    \"distance_m_roads\",\n",
    "    \"distance_m_rivers\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_expr = [(pl.col(col) * lattice_weight_multiplier).mean() for col in aggregated_cols]\n",
    "\n",
    "aggregated_metrics = (\n",
    "    features_df.select([\"quadkey\"] + aggregated_cols)\n",
    "    .rename({\"quadkey\": \"lattice_quadkey\"})\n",
    "    .join(\n",
    "        lattice_df,\n",
    "        on=\"lattice_quadkey\",\n",
    "        how=\"inner\",\n",
    "        validate=\"1:m\",\n",
    "    )\n",
    "    .drop(\"lattice_quadkey\")\n",
    "    .with_columns(chebyshev_count_exprs)\n",
    "    .with_columns(lattice_weight_exprs)\n",
    "    .group_by(\"center_quadkey\")\n",
    "    .agg(agg_expr)\n",
    "    .rename({\"center_quadkey\": \"quadkey\"})\n",
    "    .sort(by=\"quadkey\")\n",
    ")\n",
    "print(len(aggregated_metrics))\n",
    "aggregated_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_metrics = aggregated_metrics.with_columns(\n",
    "    pl.all().name.suffix(f\"_lattice_{LATTICE_RADIUS}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_metrics = aggregated_metrics.select(f\"^.*_lattice_{LATTICE_RADIUS}$\").rename(\n",
    "    {f\"quadkey_lattice_{LATTICE_RADIUS}\": \"quadkey\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation for lithology type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_metrics = (\n",
    "    features_df.select([\"quadkey\"] + [\"lithology_type\"])\n",
    "    .rename({\"quadkey\": \"lattice_quadkey\"})\n",
    "    .join(\n",
    "        lattice_df,\n",
    "        on=\"lattice_quadkey\",\n",
    "        how=\"inner\",\n",
    "        validate=\"1:m\",\n",
    "    )\n",
    "    .drop(\"lattice_quadkey\")\n",
    "    .with_columns(chebyshev_count_exprs)\n",
    "    .with_columns(lattice_weight_exprs)\n",
    "    .group_by(\"center_quadkey\")\n",
    "    .agg(pl.col(\"lithology_type\").mode())\n",
    "    .rename(\n",
    "        {\n",
    "            \"center_quadkey\": \"quadkey\",\n",
    "            \"lithology_type\": f\"lithology_type_lattice_{LATTICE_RADIUS}\",\n",
    "        }\n",
    "    )\n",
    "    .sort(by=\"quadkey\")\n",
    ")\n",
    "print(len(lithology_metrics))\n",
    "lithology_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first element from mode list\n",
    "lithology_metrics = (\n",
    "    lithology_metrics.with_row_index()\n",
    "    .with_columns(\n",
    "        pl.col(f\"lithology_type_lattice_{LATTICE_RADIUS}\")\n",
    "        .explode()\n",
    "        .gather(0)\n",
    "        .over(pl.col(\"index\"))\n",
    "    )\n",
    "    .drop(\"index\")\n",
    ")\n",
    "lithology_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation for soilclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soilclass_metrics = (\n",
    "    features_df.select([\"quadkey\"] + [\"soil_class\"])\n",
    "    .rename({\"quadkey\": \"lattice_quadkey\"})\n",
    "    .join(\n",
    "        lattice_df,\n",
    "        on=\"lattice_quadkey\",\n",
    "        how=\"inner\",\n",
    "        validate=\"1:m\",\n",
    "    )\n",
    "    .drop(\"lattice_quadkey\")\n",
    "    .with_columns(chebyshev_count_exprs)\n",
    "    .with_columns(lattice_weight_exprs)\n",
    "    .group_by(\"center_quadkey\")\n",
    "    .agg(pl.col(\"soil_class\").mode())\n",
    "    .rename(\n",
    "        {\n",
    "            \"center_quadkey\": \"quadkey\",\n",
    "            \"soil_class\": f\"soil_class_lattice_{LATTICE_RADIUS}\",\n",
    "        }\n",
    "    )\n",
    "    .sort(by=\"quadkey\")\n",
    ")\n",
    "print(len(soilclass_metrics))\n",
    "soilclass_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first element from mode list\n",
    "soilclass_metrics = (\n",
    "    soilclass_metrics.with_row_index()\n",
    "    .with_columns(\n",
    "        pl.col(f\"soil_class_lattice_{LATTICE_RADIUS}\")\n",
    "        .explode()\n",
    "        .gather(0)\n",
    "        .over(pl.col(\"index\"))\n",
    "    )\n",
    "    .drop(\"index\")\n",
    ")\n",
    "soilclass_metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lattice features to train df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_features = (\n",
    "    features_df.join(lithology_metrics, on=\"quadkey\")\n",
    "    .join(soilclass_metrics, on=\"quadkey\")\n",
    "    .join(aggregated_metrics, on=\"quadkey\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_features.write_parquet(OUTPUT_FPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice_features[\"MOV_TYPE\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
